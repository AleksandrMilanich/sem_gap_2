{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Вторая лабораторная\n",
    "\n",
    "Лабораторная состоит из гайда по базовым методам обработки изображений на Python, двух обязательных заданий и одного дополнительного:\n",
    "\n",
    "* [Задание 1](#Задание-1.) - подбор изображения, на котором преобразование Хафа находит прямые;\n",
    "* [Задание 2](#Задание-2.) - сегментация (выделение объекта на изображении) поиском границ;\n",
    "* [Задание 3 (дополнительное)](#Задание-3-(дополнительное)) - перспективное преобразование.\n",
    "\n",
    "Сначала рекомендуется ознакомиться с гайдом, после чего выполнять задания.\n",
    "\n",
    "*В этом ноутбуке изначально опущены результаты исполнения кода. Рекомендуется запускать (Ctrl+Enter) ячейки по мере просмотра документа*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from imageio import imread, imsave\n",
    "from skimage.color import rgb2gray\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Преобразование Хафа\n",
    "\n",
    "Достаточно часто возникает задача распознавания геометрических объектов (прямых, окружностей и т.п.)\n",
    "\n",
    "Найдём границы куба с помощью преобразования Хафа:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage.transform import (hough_line, hough_line_peaks,\n",
    "                               probabilistic_hough_line)\n",
    "from skimage.feature import canny\n",
    "\n",
    "from matplotlib import cm\n",
    "\n",
    "def show_hough_transform(image):\n",
    "    h, theta, d = hough_line(canny(image))  # вычисляем преобразование Хафа от границ изображения\n",
    "\n",
    "    fig, ax = plt.subplots(1, 3, figsize=(15, 6))\n",
    "\n",
    "    ax[0].imshow(image, cmap=cm.gray)\n",
    "    ax[0].set_title('Input image')\n",
    "    ax[0].set_axis_off()\n",
    "\n",
    "    ax[1].imshow(np.log(1 + h),\n",
    "                 extent=[np.rad2deg(theta[-1]), np.rad2deg(theta[0]), d[-1], d[0]],\n",
    "                 cmap='gray', aspect=1/20)\n",
    "    ax[1].set_title('Hough transform')\n",
    "    ax[1].set_xlabel('Angles (degrees)')\n",
    "    ax[1].set_ylabel('Distance (pixels)')\n",
    "\n",
    "    ax[2].imshow(image, cmap=cm.gray)\n",
    "    for _, angle, dist in zip(*hough_line_peaks(h, theta, d)):\n",
    "        y0 = (dist - 0 * np.cos(angle)) / np.sin(angle)\n",
    "        y1 = (dist - image.shape[1] * np.cos(angle)) / np.sin(angle)\n",
    "        ax[2].plot((0, image.shape[1]), (y0, y1), '-r')\n",
    "    ax[2].set_xlim((0, image.shape[1]))\n",
    "    ax[2].set_ylim((image.shape[0], 0))\n",
    "    ax[2].set_axis_off()\n",
    "    ax[2].set_title('Detected lines')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    \n",
    "cube = rgb2gray(imread('./cube.jpg'))\n",
    "show_hough_transform(cube)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### Задание 1.\n",
    "\n",
    "Подберите изображение, на котором с помощью преобразования Хафа можно найти несколько прямых:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_with_lines = rgb2gray(imread('<your image>'))\n",
    "\n",
    "show_hough_transform(image_with_lines)\n",
    "plt.savefig('task_1.png', dpi=150)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Поиск границ\n",
    "\n",
    "Часто возникает задача поиска границ на изображении: они могут быть использованы для распознавания образов (Object Detection), сегментации и классификации изображений. Так, в предыдущей задаче поиск линий осуществлялся именно на карте границ, а не на исходном изображении.\n",
    "\n",
    "Посмотрим на различные фильтры, помогающие при выделении границ:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage.filters import roberts, sobel, scharr, prewitt\n",
    "from skimage.feature import canny\n",
    "\n",
    "matchbox = rgb2gray(imread('matchbox.jpg')) # детекторы границ по умолчанию работают с одним каналом\n",
    "\n",
    "fig, ax = plt.subplots(2, 3, figsize=(15, 6))\n",
    "ax[0, 0].imshow(matchbox, cmap='gray')\n",
    "ax[0, 1].imshow(roberts(matchbox), cmap='gray')\n",
    "ax[0, 2].imshow(sobel(matchbox), cmap='gray')\n",
    "ax[1, 0].imshow(scharr(matchbox), cmap='gray')\n",
    "ax[1, 1].imshow(prewitt(matchbox), cmap='gray')\n",
    "ax[1, 2].imshow(canny(matchbox), cmap='gray')\n",
    "for i, title in enumerate([\"Input\", \"Roberts\", \"Sobel\", \"Scharr\", \"Prewitt\", \"Canny\"]): ax.flatten()[i].set_title(title)\n",
    "for i in range(6): ax.flatten()[i].set_axis_off()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Фильтры Roberts, Sobel, Scharr, Prewitt вычисляют различные аппроксимации модуля градиента.\n",
    "\n",
    "Детектор Canny - находит тонкие границы, соответствующие локальным максимумам модуля градиента. Поэтому зачастую граница состоит из набора коротких кривых. И для edge-based сегментации (выделения полного контура объекта) с помощью детектора Canny требуется подбирать параметры.\n",
    "\n",
    "Выделим спичечный коробок на изображении двумя способами: с помощью карты границ, полученной детектором Canny, и с помощью так называемой region-based сегментации - методом [водораздела](https://en.wikipedia.org/wiki/Watershed_%28image_processing%29), применяя аппроксимацию модуля градиента Собеля."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from scipy.ndimage.morphology import binary_fill_holes\n",
    "from skimage.segmentation import watershed\n",
    "from skimage.morphology import binary_closing, binary_erosion\n",
    "from skimage.color import label2rgb\n",
    "\n",
    "fig, ax = plt.subplots(1, 4, figsize=(15, 6))\n",
    "\n",
    "canny_edge_map = binary_closing(canny(matchbox, sigma=1), selem=np.ones((4, 4)))\n",
    "matchbox_edge_segmentation = binary_fill_holes(canny_edge_map)\n",
    "\n",
    "ax[0].imshow(canny_edge_map, cmap='gray')\n",
    "ax[1].imshow(label2rgb(matchbox_edge_segmentation, image=matchbox, bg_label=2))\n",
    "\n",
    "# поставим маркеры фона и объекта\n",
    "markers = np.zeros_like(matchbox)\n",
    "markers[0:10, 0:10] = 1 # маркеры фона\n",
    "markers[binary_erosion(canny_edge_map) > 0] = 2 # маркеры объекта - точки, находящиеся заведомо внутри\n",
    "\n",
    "sobel_gradient = sobel(matchbox)\n",
    "matchbox_region_segmentation = watershed(sobel_gradient, markers)\n",
    "\n",
    "ax[2].imshow(sobel_gradient, cmap='gray')\n",
    "ax[3].imshow(label2rgb(matchbox_region_segmentation, image=matchbox, bg_label=0))\n",
    "\n",
    "for i, title in enumerate([\"Canny dilated edges\", \"Edge-based segmentation\", \"Gradient magnitude\", \"Region-based segmentation\"]): ax[i].set_title(title)\n",
    "for i in range(3): ax[i].set_axis_off()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Визуально оба метода справились достаточно хорошо, но у каждого есть свои недостатки и преимущества:\n",
    "* edge-based сегментация в данном случае дала не совсем корректный результат (в маску вошли две лишние кривые, идущие по тени), при этом вручную были подобраны параметры фильтра и ядра дилатации;\n",
    "* для region-based пришлось вручную задать маркеры объекта - на практике такой информации могло бы и не быть."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### Задание 2.\n",
    "* Подберите изображение, на котором можно выделить объект первым подходом (с помощью карты границ). При этом на изображении должен быть неоднородный фон;\n",
    "* Найдите параметры детектора границ и морфологических операций, чтобы получить максимально точную маску."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "easy_to_segment = rgb2gray(imread('<your image>'))\n",
    "\n",
    "my_edge_map = binary_closing(canny(easy_to_segment, sigma=1), selem=np.ones((4, 4)))\n",
    "my_edge_segmentation = binary_fill_holes(my_edge_map)\n",
    "\n",
    "plt.imshow(label2rgb(my_edge_segmentation, image=easy_to_segment))\n",
    "plt.savefig('task_2.png', dpi=150)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "\n",
    "## Особые точки \n",
    "\n",
    "Особые точки - один из основных механизмов извлечения признаков для распознавания образов и локализации заданного объекта на изображении.\n",
    "\n",
    "Существует несколько типов особых точек и дескрипторов:\n",
    "* инвариантные к сдвигу, масштабированию и повороту - SIFT, SURF, FAST;\n",
    "* инвариантные к масштабированию, но не к повороту - U-SURF;\n",
    "* не инвариантные к масштабированию - Blob (обычно дескрипторы описывают соответствующие точки, но с разным значением радиуса);\n",
    "* и другие.\n",
    "\n",
    "Посмотрим на результаты работы различных детекторов:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from skimage.feature import corner_harris, corner_peaks, corner_fast, corner_subpix\n",
    "from skimage.transform import warp, AffineTransform\n",
    "\n",
    "basketball = rgb2gray(imread(\"basketball.jpg\"))\n",
    "\n",
    "fig, ax = plt.subplots(1, 3, figsize=(15, 6))\n",
    "ax[0].set_title('Image')\n",
    "ax[0].imshow(basketball, cmap='gray')\n",
    "\n",
    "# corner_harris возвращает матрицу, в которой максимумы соответствуют особым точкам\n",
    "# поэтому чтобы извлечь координаты надо вызвать corner_peaks\n",
    "basketball_harris = corner_peaks(corner_harris(basketball), threshold_rel=0.1)\n",
    "ax[1].set_title('Harris')\n",
    "ax[1].imshow(basketball, cmap='gray')\n",
    "ax[1].plot(basketball_harris[:, 1], basketball_harris[:, 0], '+b', markersize=2)\n",
    "\n",
    "basketball_fast = corner_peaks(corner_fast(basketball), threshold_rel=0.1)\n",
    "ax[2].set_title('FAST')\n",
    "ax[2].imshow(basketball, cmap='gray')\n",
    "ax[2].plot(basketball_fast[:, 1], basketball_fast[:, 0], '+b', markersize=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Решим задачу стабилизации видеоряда: дана последовательность изображений (для простоты - два), требуется сделать так, чтобы объект занимал одно и то же положение в кадре.\n",
    "\n",
    "Сначала сгенирируем данные искусственным образом: пусть камера немного повернулась против часовой стрелки и сдвинулась вверх.\n",
    "Получим новую картинку поворотом старой на 3 градуса и сдвигом на 20 пикселей вправо и вниз, и посмотрим на особые точки:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage.transform import warp, AffineTransform\n",
    "\n",
    "tform = AffineTransform(rotation=np.deg2rad(3), translation=(20, 20))\n",
    "basketball2 = warp(basketball, tform.inverse, output_shape=basketball.shape)\n",
    "\n",
    "fig, ax = plt.subplots(1, 3, figsize=(15, 6))\n",
    "ax[0].imshow(basketball2, cmap='gray')\n",
    "\n",
    "basketball2_harris = corner_peaks(corner_harris(basketball2), threshold_rel=0.1)\n",
    "ax[1].imshow(basketball2, cmap='gray')\n",
    "ax[1].plot(basketball2_harris[:, 1], basketball2_harris[:, 0], '+b', markersize=2)\n",
    "\n",
    "basketball2_fast = corner_peaks(corner_fast(basketball2), threshold_rel=0.1)\n",
    "ax[2].imshow(basketball2, cmap='gray')\n",
    "ax[2].plot(basketball2_fast[:, 1], basketball2_fast[:, 0], '+b', markersize=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Видно, что часть особых точек находится в тех же местах объекта, где и была до поворота.\n",
    "\n",
    "Найдём дескрипторы особых точек исходной и искажённой картинок, и сдвинем вторую картинку, чтобы она занимала исходное положение.\n",
    "\n",
    "Для этого воспользуемся *ORB* - детектором (*Oriented FAST and rotated BRIEF*) и методом RANSAC для поиска аффинного преобразования, после чего применим обратное аффинное преобразование:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage.feature import match_descriptors, ORB\n",
    "from skimage.measure import ransac\n",
    "\n",
    "orb = ORB()\n",
    "orb.detect_and_extract(basketball)\n",
    "\n",
    "orb2 = ORB()\n",
    "orb2.detect_and_extract(basketball2)\n",
    "\n",
    "basketball_match = match_descriptors(orb.descriptors, orb2.descriptors, cross_check=True)\n",
    "\n",
    "src = orb.keypoints[basketball_match[:, 0]]\n",
    "dst = orb2.keypoints[basketball_match[:, 1]]\n",
    "    \n",
    "estimated_transform, inliers = ransac((src, dst), AffineTransform, min_samples=3,\n",
    "                               residual_threshold=2, max_trials=1000)\n",
    "\n",
    "basketball3_stab = warp(basketball2, AffineTransform(translation=estimated_transform.translation,\n",
    "                                                     rotation=-estimated_transform.rotation),\n",
    "                        output_shape=basketball2.shape)\n",
    "\n",
    "\n",
    "fig, ax = plt.subplots(1, 3, figsize=(15, 6))\n",
    "ax[0].imshow(basketball, cmap='gray')\n",
    "ax[1].imshow(basketball3_stab, cmap='gray')\n",
    "ax[2].imshow(basketball, cmap='gray', alpha=0.5)\n",
    "ax[2].imshow(basketball3_stab, cmap='gray', alpha=0.5)\n",
    "\n",
    "for i, title in enumerate(['1 кадр', 'Стабилизированный 2 кадр', 'Наложение']): ax[i].set_title(title)\n",
    "\n",
    "print(f\"Оценка сдвига: {estimated_transform.translation}\")\n",
    "print(f\"Оценка поворота: {np.rad2deg(estimated_transform.rotation)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Видно, что подход работает достаточно хорошо, поэтому его часто применяют для решения аналогичных задач на практике. Существуют и другие подходы к решению данной задачи: оценка оптического потока (Optical Flow), и сопоставление с шаблоном с помощью преобразования Фурье."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Точно такую же технику можно использовать для решения задачи поиска гомографии, в частности - проективного преобразования, то есть для поиска отображения, преобразующего шаблонное изображение (например, qr-код) в объект на другом заданном изображении (снимке с камеры). С помощью найденной (или не найденной) гомографии можно установить есть ли объект на изображении, где он находится; исправить перспективу; отрендерить 3d-объект, чтобы он реалистично вписывался в сцену (AR), и другое."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### Задание 3 (дополнительное)\n",
    "*Задание выполнять не обязательно, но оно позволяет получить дополнительный балл за лабораторную.*\n",
    "\n",
    "* Подберите два изображения, таких, что объект из первого изображения присутствует на втором изображении (можно сделать две фотографии: объекта отдельно и объекта в окружении), см. пример внизу;\n",
    "* Найдите гомографию, используя метод `cv2.findHomography` и один из способов поиска особых точек;\n",
    "* Задайте на первом изображении четырёхугольник, ограничивающий объект;\n",
    "* Обведите четырёхугольником найденный объект на втором изображении, используя `cv2.warpPerspective` или `cv2.perspectiveTransform`;\n",
    "* Сохрание в файл `task_3.png` результат - картинку, на которой слева первое изображение с четырёхугольником, ограничивающим объект (этот четырёхугольник задавался вручную), справа - второе изображение с четырёхугольников, ограничивающим объект (этот четырёхугольник был получен перспективным преобразованием).\n",
    "\n",
    "![Homography](https://www.learnopencv.com/wp-content/uploads/2016/01/homography-example.jpg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
