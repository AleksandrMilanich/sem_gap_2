{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Вторая лабораторная. Обработка изображений\n",
    "\n",
    "Лабораторная состоит из гайда по базовым методам обработки изображений на Python, двух обязательных заданий и одного дополнительного (дополнительное задание может принести +2 балла):\n",
    "\n",
    "* [Задание 1](#Задание-1.) - подбор изображения, на котором преобразование Хафа находит прямые;\n",
    "* [Задание 2](#Задание-2.) - сегментация (выделение объекта на изображении) поиском границ;\n",
    "* [Задание 3 (дополнительное)](#Задание-3-(дополнительное)) - перспективное преобразование.\n",
    "\n",
    "Сначала рекомендуется ознакомиться с гайдом, после чего выполнять задания.\n",
    "\n",
    "*В этом ноутбуке изначально опущены результаты исполнения кода. Рекомендуется запускать (Ctrl+Enter) ячейки по мере просмотра документа*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Используемые модули\n",
    "\n",
    "Установим необходимые модули:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Подключим модули, которые пригодятся в мини-лабораторной."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from imageio import imread, imsave\n",
    "from skimage.color import rgb2gray, label2rgb\n",
    "from skimage.transform import hough_line, hough_line_peaks, warp, AffineTransform\n",
    "from skimage.feature import canny, corner_harris, corner_peaks, corner_fast, corner_subpix, match_descriptors, ORB\n",
    "from skimage.filters import roberts, sobel, scharr, prewitt\n",
    "from skimage.segmentation import watershed\n",
    "from skimage.morphology import binary_closing, binary_erosion\n",
    "from skimage.measure import ransac\n",
    "from scipy import ndimage as ndi\n",
    "import cv2\n",
    "import os\n",
    "from save_answer import add_to_answer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Преобразование Хафа\n",
    "\n",
    "Достаточно часто возникает задача распознавания геометрических объектов (прямых, окружностей и т.п.)\n",
    "\n",
    "Найдём границы куба с помощью преобразования Хафа:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_hough_transform(image, threshold=100):\n",
    "    borders = canny(image)  # вычисляем преобразование Хафа от границ изображения\n",
    "    h, theta, d = hough_line(borders)\n",
    "    \n",
    "    fig, ax = plt.subplots(1, 3, figsize=(15, 6))\n",
    "\n",
    "    ax[0].imshow(image, cmap='gray')\n",
    "    ax[0].set_title('Input image')\n",
    "    ax[0].set_axis_off()\n",
    "\n",
    "    ax[1].imshow(np.log(1 + h),\n",
    "                 extent=[np.rad2deg(theta[-1]), np.rad2deg(theta[0]), d[-1], d[0]],\n",
    "                 cmap='gray', aspect=1/20)\n",
    "    ax[1].set_title('Hough transform')\n",
    "    ax[1].set_xlabel('Angles (degrees)')\n",
    "    ax[1].set_ylabel('Distance (pixels)')\n",
    "\n",
    "    ax[2].imshow(image, cmap='gray')\n",
    "    # hough_line_peaks возвращает кортеж из трёх списков.\n",
    "    # Чтобы удобно было итерироваться в цикле, мы разворачиваем списки\n",
    "    # с помощью звёздочки, потом снова заворачиваем с помощью zip,\n",
    "    # чтобы итерироваться по списку кортежей-троек.\n",
    "    for _, angle, dist in zip(*hough_line_peaks(h, theta, d, threshold=threshold)):\n",
    "        # Переводим полярные координаты в декартовы, чтобы отрисовать\n",
    "        (x0, y0) = dist * np.array([np.cos(angle), np.sin(angle)])\n",
    "        # Рисуем линию по точке и направлению\n",
    "        ax[2].axline((x0, y0), slope=np.tan(angle + np.pi/2), c='r', ls='-')\n",
    "    ax[2].set_xlim((0, image.shape[1]))\n",
    "    ax[2].set_ylim((image.shape[0], 0))\n",
    "    ax[2].set_axis_off()\n",
    "    ax[2].set_title('Detected lines')\n",
    "\n",
    "    plt.tight_layout()\n",
    "\n",
    "cube = rgb2gray(imread(os.path.join(\"images\", \"cube.jpg\")))\n",
    "show_hough_transform(cube, threshold=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### Задание 1.\n",
    "\n",
    "Подберите изображение, на котором с помощью преобразования Хафа можно найти несколько прямых (не менее четырёх):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_file = os.path.join(\"images\", \"<your image>\")\n",
    "\n",
    "image_as_gray = rgb2gray(imread(image_file))\n",
    "\n",
    "# Параметр threshold можно менять\n",
    "threshold = 100\n",
    "show_hough_transform(image_as_gray, threshold=threshold)\n",
    "result_image = os.path.join(\"images\", \"task_1.png\")\n",
    "plt.savefig(result_image, dpi=150)\n",
    "\n",
    "# Сохранение результатов\n",
    "add_to_answer(\n",
    "    \"task_1\",\n",
    "    {\n",
    "        \"source_image\": image_file,\n",
    "        \"result_image\": result_image,\n",
    "        \"threshold\": threshold,\n",
    "    },\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Поиск границ\n",
    "\n",
    "Часто возникает задача поиска границ на изображении: они могут быть использованы для распознавания образов (Object Detection), сегментации и классификации изображений. Так, в предыдущей задаче поиск линий осуществлялся именно на карте границ, а не на исходном изображении.\n",
    "\n",
    "Посмотрим на различные фильтры, помогающие при выделении границ:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# детекторы границ по умолчанию работают с одним каналом, поэтому используем rgb2gray\n",
    "matchbox = rgb2gray(imread(os.path.join(\"images\", \"matchbox.jpg\")))\n",
    "\n",
    "fig, ax = plt.subplots(2, 3, figsize=(15, 6))\n",
    "ax[0, 0].imshow(matchbox, cmap='gray')\n",
    "ax[0, 1].imshow(roberts(matchbox), cmap='gray')\n",
    "ax[0, 2].imshow(sobel(matchbox), cmap='gray')\n",
    "ax[1, 0].imshow(scharr(matchbox), cmap='gray')\n",
    "ax[1, 1].imshow(prewitt(matchbox), cmap='gray')\n",
    "ax[1, 2].imshow(canny(matchbox), cmap='gray')\n",
    "for i, title in enumerate([\"Input\", \"Roberts\", \"Sobel\", \"Scharr\", \"Prewitt\", \"Canny\"]): ax.flatten()[i].set_title(title)\n",
    "for i in range(6): ax.flatten()[i].set_axis_off()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Фильтры Roberts, Sobel, Scharr, Prewitt вычисляют различные аппроксимации модуля градиента.\n",
    "\n",
    "Детектор Canny - находит тонкие границы, соответствующие локальным максимумам модуля градиента. Поэтому зачастую граница состоит из набора коротких кривых. И для edge-based сегментации (выделения полного контура объекта) с помощью детектора Canny требуется подбирать параметры.\n",
    "\n",
    "Выделим спичечный коробок на изображении двумя способами: с помощью карты границ, полученной детектором Canny, и с помощью так называемой region-based сегментации - методом [водораздела](https://en.wikipedia.org/wiki/Watershed_%28image_processing%29), применяя аппроксимацию модуля градиента Собеля."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 4, figsize=(15, 6))\n",
    "\n",
    "# Применяем фильтр canny, чтобы выделить кривые. Поверх маски с результатом\n",
    "# применяем морфологическое закрытие, чтобы немного продлить границы.\n",
    "# Продление границ нужно, чтобы основные контуры, очерчивающие объект, замкнулись\n",
    "canny_edge_map = binary_closing(canny(matchbox, sigma=1), footprint=np.ones((4, 4)))\n",
    "\n",
    "# По краям изображения фильтр canny тоже находит границы, для корректной работы\n",
    "# binary_fill_holes (\"закрашивание дыр\") эти границы следует убрать\n",
    "def correct_mask_borders_after_canny(canny_result, border_width=3):\n",
    "    # заполняем полосы толщиной border_width нулями\n",
    "    canny_result[:border_width,:] = 0\n",
    "    canny_result[:,:border_width] = 0\n",
    "    canny_result[-border_width:,:] = 0\n",
    "    canny_result[:,-border_width:] = 0\n",
    "\n",
    "correct_mask_borders_after_canny(canny_edge_map)\n",
    "# Заполняем \"дыры\", чтобы маска соответствовала объекту\n",
    "matchbox_edge_segmentation = ndi.binary_fill_holes(canny_edge_map)\n",
    "\n",
    "ax[0].imshow(canny_edge_map, cmap='gray')\n",
    "ax[1].imshow(label2rgb(matchbox_edge_segmentation.astype(int), image=matchbox, bg_label=2))\n",
    "\n",
    "# поставим маркеры фона и объекта\n",
    "markers = np.zeros_like(matchbox)  # создаём матрицу markers того же размера и типа, как matchbox\n",
    "markers[0:10, 0:10] = 1 # ставим маркеры фона\n",
    "markers[binary_erosion(canny_edge_map) > 0] = 2 # ставим маркеры объекта - точки, находящиеся заведомо внутри\n",
    "\n",
    "sobel_gradient = sobel(matchbox)\n",
    "matchbox_region_segmentation = watershed(sobel_gradient, markers)\n",
    "\n",
    "ax[2].imshow(sobel_gradient, cmap='gray')\n",
    "ax[3].imshow(label2rgb(matchbox_region_segmentation, image=matchbox, bg_label=0))\n",
    "\n",
    "for i, title in enumerate([\"Canny dilated edges\", \"Edge-based segmentation\", \"Gradient magnitude\", \"Region-based segmentation\"]): ax[i].set_title(title)\n",
    "for i in range(3): ax[i].set_axis_off()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Визуально оба метода справились достаточно хорошо, но у каждого есть свои недостатки и преимущества:\n",
    "* edge-based сегментация в данном случае дала не совсем корректный результат (в маску вошли две лишние кривые, идущие по тени), при этом вручную были подобраны параметры фильтра и ядра дилатации;\n",
    "* для region-based пришлось вручную задать маркеры объекта - на практике такой информации могло бы и не быть."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### Задание 2.\n",
    "\n",
    "* Подберите изображение, на котором можно выделить объект первым подходом (с помощью карты границ). При этом на изображении должен быть **неоднородный** фон;\n",
    "* Подберите параметры детектора границ и морфологических операций, чтобы получить максимально точную маску."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "segment_image_file = os.path.join(\"images\", \"<your image>\")\n",
    "easy_to_segment = rgb2gray(imread(segment_image_file))\n",
    "\n",
    "# Эти параметры можно менять\n",
    "canny_sigma = 1\n",
    "canny_low_threshold = None\n",
    "canny_high_threshold = None\n",
    "binary_closing_footprint_width = 4\n",
    "binary_closing_footprint = np.ones((binary_closing_footprint_width, binary_closing_footprint_width))\n",
    "\n",
    "my_edge_map = binary_closing(\n",
    "    canny(\n",
    "        easy_to_segment,\n",
    "        sigma=canny_sigma,\n",
    "        low_threshold=canny_low_threshold,\n",
    "        high_threshold=canny_high_threshold,\n",
    "    ),\n",
    "    footprint=binary_closing_footprint\n",
    ")\n",
    "correct_mask_borders_after_canny(my_edge_map)\n",
    "my_edge_segmentation = ndi.binary_fill_holes(my_edge_map)\n",
    "\n",
    "plt.imshow(label2rgb(my_edge_segmentation, image=easy_to_segment))\n",
    "result_image_file = os.path.join(\"images\", \"task_2.png\")\n",
    "plt.savefig(result_image_file, dpi=150)\n",
    "\n",
    "# Сохранение результатов\n",
    "add_to_answer(\n",
    "    \"task_2\",\n",
    "    {\n",
    "        \"source_image\": segment_image_file,\n",
    "        \"result_image\": result_image_file,\n",
    "        \"params\": {\n",
    "            \"canny\": {\n",
    "                \"sigma\": canny_sigma,\n",
    "                \"low_threshold\": canny_low_threshold,\n",
    "                \"high_threshold\": canny_high_threshold,\n",
    "            },\n",
    "            \"binary_closing_footprint_width\": binary_closing_footprint_width,\n",
    "        },\n",
    "    },\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "\n",
    "## Особые точки \n",
    "\n",
    "Особые точки - один из основных механизмов извлечения признаков для распознавания образов и локализации заданного объекта на изображении.\n",
    "\n",
    "Существует несколько типов особых точек и дескрипторов:\n",
    "* инвариантные к сдвигу, масштабированию и повороту - SIFT, SURF, FAST;\n",
    "* инвариантные к масштабированию, но не к повороту - U-SURF;\n",
    "* не инвариантные к масштабированию - Blob (обычно дескрипторы описывают соответствующие точки, но с разным значением радиуса);\n",
    "* и другие.\n",
    "\n",
    "Посмотрим на результаты работы различных детекторов:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "basketball = rgb2gray(imread(os.path.join(\"images\", \"basketball.jpg\")))\n",
    "\n",
    "fig, ax = plt.subplots(1, 3, figsize=(15, 6))\n",
    "ax[0].set_title('Image')\n",
    "ax[0].imshow(basketball, cmap='gray')\n",
    "\n",
    "# corner_harris возвращает матрицу, в которой максимумы соответствуют особым точкам\n",
    "# поэтому чтобы извлечь координаты надо вызвать corner_peaks\n",
    "basketball_harris = corner_peaks(corner_harris(basketball), threshold_rel=0.1)\n",
    "ax[1].set_title('Harris')\n",
    "ax[1].imshow(basketball, cmap='gray')\n",
    "ax[1].plot(basketball_harris[:, 1], basketball_harris[:, 0], '+b', markersize=2)\n",
    "\n",
    "basketball_fast = corner_peaks(corner_fast(basketball), threshold_rel=0.1)\n",
    "ax[2].set_title('FAST')\n",
    "ax[2].imshow(basketball, cmap='gray')\n",
    "ax[2].plot(basketball_fast[:, 1], basketball_fast[:, 0], '+b', markersize=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Решим задачу стабилизации видеоряда: дана последовательность изображений (для простоты - два), требуется сделать так, чтобы объект занимал одно и то же положение в кадре.\n",
    "\n",
    "Сначала сгенирируем данные искусственным образом: пусть камера немного повернулась против часовой стрелки и сдвинулась вверх.\n",
    "Получим новую картинку поворотом старой на 3 градуса и сдвигом на 20 пикселей вправо и вниз, и посмотрим на особые точки:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tform = AffineTransform(rotation=np.deg2rad(3), translation=(20, 20))\n",
    "basketball2 = warp(basketball, tform.inverse, output_shape=basketball.shape)\n",
    "\n",
    "fig, ax = plt.subplots(1, 3, figsize=(15, 6))\n",
    "ax[0].imshow(basketball2, cmap='gray')\n",
    "\n",
    "basketball2_harris = corner_peaks(corner_harris(basketball2), threshold_rel=0.1)\n",
    "ax[1].imshow(basketball2, cmap='gray')\n",
    "ax[1].plot(basketball2_harris[:, 1], basketball2_harris[:, 0], '+b', markersize=2)\n",
    "\n",
    "basketball2_fast = corner_peaks(corner_fast(basketball2), threshold_rel=0.1)\n",
    "ax[2].imshow(basketball2, cmap='gray')\n",
    "ax[2].plot(basketball2_fast[:, 1], basketball2_fast[:, 0], '+b', markersize=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Видно, что часть особых точек находится в тех же местах объекта, где и была до поворота.\n",
    "\n",
    "Найдём дескрипторы особых точек исходной и искажённой картинок, и сдвинем вторую картинку, чтобы она занимала исходное положение.\n",
    "\n",
    "Для этого воспользуемся *ORB* - детектором (*Oriented FAST and rotated BRIEF*) и методом RANSAC для поиска аффинного преобразования, после чего применим обратное аффинное преобразование:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "orb = ORB()\n",
    "orb.detect_and_extract(basketball)\n",
    "\n",
    "orb2 = ORB()\n",
    "orb2.detect_and_extract(basketball2)\n",
    "\n",
    "basketball_match = match_descriptors(orb.descriptors, orb2.descriptors, cross_check=True)\n",
    "\n",
    "src = orb.keypoints[basketball_match[:, 0]]\n",
    "dst = orb2.keypoints[basketball_match[:, 1]]\n",
    "    \n",
    "estimated_transform, inliers = ransac((src, dst), AffineTransform, min_samples=3,\n",
    "                               residual_threshold=2, max_trials=1000)\n",
    "\n",
    "basketball3_stab = warp(basketball2, AffineTransform(translation=estimated_transform.translation,\n",
    "                                                     rotation=-estimated_transform.rotation),\n",
    "                        output_shape=basketball2.shape)\n",
    "\n",
    "\n",
    "fig, ax = plt.subplots(1, 3, figsize=(15, 6))\n",
    "ax[0].imshow(basketball, cmap='gray')\n",
    "ax[1].imshow(basketball3_stab, cmap='gray')\n",
    "ax[2].imshow(basketball, cmap='gray', alpha=0.5)\n",
    "ax[2].imshow(basketball3_stab, cmap='gray', alpha=0.5)\n",
    "\n",
    "for i, title in enumerate(['1 кадр', 'Стабилизированный 2 кадр', 'Наложение']): ax[i].set_title(title)\n",
    "\n",
    "print(f\"Оценка сдвига: {estimated_transform.translation}\")\n",
    "print(f\"Оценка поворота: {np.rad2deg(estimated_transform.rotation)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Видно, что подход работает достаточно хорошо, поэтому его часто применяют для решения аналогичных задач на практике. Существуют и другие подходы к решению данной задачи: оценка оптического потока (Optical Flow), и сопоставление с шаблоном с помощью преобразования Фурье."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Точно такую же технику можно использовать для решения задачи поиска гомографии, в частности - проективного преобразования, то есть для поиска отображения, преобразующего шаблонное изображение (например, qr-код) в объект на другом заданном изображении (снимке с камеры). С помощью найденной (или не найденной) гомографии можно установить есть ли объект на изображении, где он находится; исправить перспективу; отрендерить 3d-объект, чтобы он реалистично вписывался в сцену (AR), и другое."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### Задание 3 (дополнительное)\n",
    "*Задание выполнять не обязательно, но оно позволяет получить 2 дополнительных балла за лабораторную.*\n",
    "\n",
    "* Подберите два изображения, таких, что объект из первого изображения присутствует на втором изображении (можно сделать две фотографии: объекта отдельно и объекта в окружении), см. пример внизу;\n",
    "* Найдите гомографию, используя метод `cv2.findHomography` и один из способов поиска особых точек;\n",
    "* Задайте на первом изображении четырёхугольник, ограничивающий объект;\n",
    "* Обведите четырёхугольником найденный объект на втором изображении, используя `cv2.warpPerspective` или `cv2.perspectiveTransform`;\n",
    "* Сохрание в файл `task_3_result.png` результат - картинку, на которой слева первое изображение с четырёхугольником, ограничивающим объект (этот четырёхугольник задавался вручную), справа - второе изображение с четырёхугольников, ограничивающим объект (этот четырёхугольник был получен перспективным преобразованием).\n",
    "\n",
    "_Пояснение:_ четырёхугольник, ограничивающий объект, вручную задаётся для первого изображения. С помощью перспективного преобразования (которое найдено по сопоставлению особых точек) этот четырёхугольник переносится на второе изображение, где его образ тоже является четырёхугольником, ограничивающим объект. При этом на **втором** изображении **не нужно** задавать ограничивающий многоугольник вручную: он должен получиться автоматически в результате применения перспективного преобразования.\n",
    "\n",
    "![Homography](https://www.learnopencv.com/wp-content/uploads/2016/01/homography-example.jpg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "source_image_file_first = os.path.join(\"images\", \"<your image>\")\n",
    "source_image_file_second = os.path.join(\"images\", \"<your another image>\")\n",
    "result_image_file = os.path.join(\"images\", \"task_3_result.png\")\n",
    "\n",
    "\n",
    "# Напишите здесь код для решения задания\n",
    "\n",
    "\n",
    "# Сохраните картинку с двумя \"подграфиками\":\n",
    "#  - на первом: первую картинку с нарисованным поверх ограничивающим 4-угольником, заданным вручную\n",
    "#  - на втором: вторую картинку с нарисованным поверх вычисленным ограничивающим 4-угольником\n",
    "plt.savefig(result_image_file, dpi=150)\n",
    "\n",
    "# Сохранение результатов\n",
    "add_to_answer(\n",
    "    \"task_3\",\n",
    "    {\n",
    "        \"source_image_file_first\": source_image_file_first,\n",
    "        \"source_image_file_second\": source_image_file_second,\n",
    "        \"result_image\": result_image_file,\n",
    "    },\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
